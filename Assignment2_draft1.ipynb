{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6427 images in training set, 1070 in test set.\n",
    "##### label: \n",
    "##### 0 -> Normal, which is 0 in the image\n",
    "##### 1 -> Anomaly, image is not 0\n",
    "##### Training label given, need to predict output of test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load images to features and labels\n",
    "def load_images_to_data(image_directory):\n",
    "    list_of_files = os.listdir(image_directory)\n",
    "    features_data = np.empty((0,28,28,1),dtype=\"float32\")\n",
    "    for file in tqdm(list_of_files):\n",
    "        image_file_name = os.path.join(image_directory, file)\n",
    "        if \".jpg\" in image_file_name:\n",
    "            img = Image.open(image_file_name)\n",
    "            img = np.resize(img, (28,28,1))\n",
    "            im2arr = np.array(img)\n",
    "            im2arr = im2arr.reshape(1,28,28,1)\n",
    "            features_data = np.append(features_data, im2arr, axis=0)\n",
    "    return features_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory = './bt4012-in-class-competition/train_images/'\n",
    "test_directory = './bt4012-in-class-competition/test_images/'\n",
    "train_label_directory = './bt4012-in-class-competition/train.csv'\n",
    "#pre_label_directory = './bt4012-in-class-competition/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6427/6427 [01:01<00:00, 105.12it/s]\n",
      "100%|██████████| 1070/1070 [00:02<00:00, 472.31it/s]\n"
     ]
    }
   ],
   "source": [
    "X = load_images_to_data(train_directory)\n",
    "y = pd.read_csv(train_label_directory)['label'].values.astype(np.int)\n",
    "X_pred = load_images_to_data(test_directory)\n",
    "#y_pred = pd.read_csv(pre_label_directory)['label'].values.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in more data from library\n",
    "from keras.datasets import mnist\n",
    "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
    "\n",
    "# reshape new data\n",
    "trainX = trainX.reshape(trainX.shape[0], 28, 28, 1).astype('float32')\n",
    "testX = testX.reshape(testX.shape[0], 28, 28, 1).astype('float32')\n",
    "trainy = np.array(list(map(lambda x: 0 if x==0 else 1, trainy)))\n",
    "testy = np.array(list(map(lambda x: 0 if x==0 else 1, testy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append\n",
    "X_train = np.append(X_train, trainX, axis = 0)\n",
    "X_test = np.append(X_test, testX, axis = 0)\n",
    "y_train = np.append(y_train, trainy, axis = 0)\n",
    "y_test = np.append(y_test, testy, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersampling\n",
    "y_train_df = pd.DataFrame(y_train, columns=['y'])\n",
    "positive_class = y_train_df[y_train_df.y==1].index.tolist()\n",
    "negative_class = y_train_df[y_train_df.y==0].index.tolist()\n",
    "positive_class = positive_class[0:10000]\n",
    "positive_class.extend(negative_class)\n",
    "X_train = X_train[positive_class]\n",
    "y_train = y_train[positive_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale down the data \n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_pred /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = 2\n",
    "y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
    "y_test = np_utils.to_categorical(y_test, number_of_classes)\n",
    "y_pred = np_utils.to_categorical(y_pred, number_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (5, 5), input_shape=(X_train.shape[1], X_train.shape[2], 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "104/104 [==============================] - 15s 142ms/step - loss: 0.0939 - auc_11: 0.9930 - val_loss: 0.4928 - val_auc_11: 0.8614\n",
      "Epoch 2/50\n",
      "104/104 [==============================] - 13s 125ms/step - loss: 0.0883 - auc_11: 0.9935 - val_loss: 0.4011 - val_auc_11: 0.8900\n",
      "Epoch 3/50\n",
      "104/104 [==============================] - 12s 116ms/step - loss: 0.0840 - auc_11: 0.9942 - val_loss: 0.3570 - val_auc_11: 0.9049\n",
      "Epoch 4/50\n",
      "104/104 [==============================] - 12s 117ms/step - loss: 0.0821 - auc_11: 0.9944 - val_loss: 0.3860 - val_auc_11: 0.8870\n",
      "Epoch 5/50\n",
      "104/104 [==============================] - 11s 106ms/step - loss: 0.0818 - auc_11: 0.9942 - val_loss: 0.4086 - val_auc_11: 0.8823\n",
      "Epoch 6/50\n",
      "104/104 [==============================] - 11s 105ms/step - loss: 0.0806 - auc_11: 0.9946 - val_loss: 0.5135 - val_auc_11: 0.8525\n",
      "Epoch 7/50\n",
      "104/104 [==============================] - 11s 106ms/step - loss: 0.0783 - auc_11: 0.9947 - val_loss: 0.5528 - val_auc_11: 0.8509\n",
      "Epoch 8/50\n",
      "104/104 [==============================] - 12s 112ms/step - loss: 0.0782 - auc_11: 0.9947 - val_loss: 0.3662 - val_auc_11: 0.8990\n",
      "Epoch 9/50\n",
      "104/104 [==============================] - 11s 109ms/step - loss: 0.0768 - auc_11: 0.9950 - val_loss: 0.4269 - val_auc_11: 0.8849\n",
      "Epoch 10/50\n",
      "104/104 [==============================] - 13s 121ms/step - loss: 0.0752 - auc_11: 0.9951 - val_loss: 0.5232 - val_auc_11: 0.8544\n",
      "Epoch 11/50\n",
      "104/104 [==============================] - 15s 148ms/step - loss: 0.0748 - auc_11: 0.9953 - val_loss: 0.5281 - val_auc_11: 0.8672\n",
      "Epoch 12/50\n",
      "104/104 [==============================] - 12s 120ms/step - loss: 0.0729 - auc_11: 0.9955 - val_loss: 0.4655 - val_auc_11: 0.8703\n",
      "Epoch 13/50\n",
      "104/104 [==============================] - 14s 137ms/step - loss: 0.0725 - auc_11: 0.9956 - val_loss: 0.4562 - val_auc_11: 0.8831\n",
      "Epoch 14/50\n",
      "104/104 [==============================] - 14s 130ms/step - loss: 0.0718 - auc_11: 0.9957 - val_loss: 0.6042 - val_auc_11: 0.8575\n",
      "Epoch 15/50\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0733 - auc_11: 0.9954 - val_loss: 0.4522 - val_auc_11: 0.8723\n",
      "Epoch 16/50\n",
      "104/104 [==============================] - 11s 109ms/step - loss: 0.0739 - auc_11: 0.9955 - val_loss: 0.4553 - val_auc_11: 0.8792\n",
      "Epoch 17/50\n",
      "104/104 [==============================] - 13s 124ms/step - loss: 0.0704 - auc_11: 0.9959 - val_loss: 0.4331 - val_auc_11: 0.8813\n",
      "Epoch 18/50\n",
      "104/104 [==============================] - 11s 107ms/step - loss: 0.0708 - auc_11: 0.9959 - val_loss: 0.4631 - val_auc_11: 0.8779\n",
      "Epoch 19/50\n",
      "104/104 [==============================] - 13s 125ms/step - loss: 0.0712 - auc_11: 0.9959 - val_loss: 0.4874 - val_auc_11: 0.8815\n",
      "Epoch 20/50\n",
      "104/104 [==============================] - 14s 130ms/step - loss: 0.0706 - auc_11: 0.9959 - val_loss: 0.4830 - val_auc_11: 0.8769\n",
      "Epoch 21/50\n",
      "104/104 [==============================] - 13s 124ms/step - loss: 0.0685 - auc_11: 0.9962 - val_loss: 0.3517 - val_auc_11: 0.9131\n",
      "Epoch 22/50\n",
      "104/104 [==============================] - 12s 114ms/step - loss: 0.0697 - auc_11: 0.9961 - val_loss: 0.3724 - val_auc_11: 0.9029\n",
      "Epoch 23/50\n",
      "104/104 [==============================] - 14s 135ms/step - loss: 0.0695 - auc_11: 0.9962 - val_loss: 0.4065 - val_auc_11: 0.8935\n",
      "Epoch 24/50\n",
      "104/104 [==============================] - 11s 108ms/step - loss: 0.0700 - auc_11: 0.9961 - val_loss: 0.5149 - val_auc_11: 0.8671\n",
      "Epoch 25/50\n",
      "104/104 [==============================] - 12s 119ms/step - loss: 0.0669 - auc_11: 0.9964 - val_loss: 0.4930 - val_auc_11: 0.8782\n",
      "Epoch 26/50\n",
      "104/104 [==============================] - 12s 116ms/step - loss: 0.0697 - auc_11: 0.9960 - val_loss: 0.4297 - val_auc_11: 0.8922\n",
      "Epoch 27/50\n",
      "104/104 [==============================] - 13s 125ms/step - loss: 0.0676 - auc_11: 0.9964 - val_loss: 0.4639 - val_auc_11: 0.8743\n",
      "Epoch 28/50\n",
      "104/104 [==============================] - 13s 125ms/step - loss: 0.0683 - auc_11: 0.9963 - val_loss: 0.4908 - val_auc_11: 0.8847\n",
      "Epoch 29/50\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.0680 - auc_11: 0.9963 - val_loss: 0.4491 - val_auc_11: 0.8776\n",
      "Epoch 30/50\n",
      "104/104 [==============================] - 13s 129ms/step - loss: 0.0675 - auc_11: 0.9964 - val_loss: 0.4062 - val_auc_11: 0.9031\n",
      "Epoch 31/50\n",
      "104/104 [==============================] - 11s 104ms/step - loss: 0.0663 - auc_11: 0.9966 - val_loss: 0.4596 - val_auc_11: 0.8821\n",
      "Epoch 32/50\n",
      "104/104 [==============================] - 13s 121ms/step - loss: 0.0648 - auc_11: 0.9968 - val_loss: 0.4368 - val_auc_11: 0.8938\n",
      "Epoch 33/50\n",
      "104/104 [==============================] - 12s 116ms/step - loss: 0.0669 - auc_11: 0.9966 - val_loss: 0.4447 - val_auc_11: 0.8924\n",
      "Epoch 34/50\n",
      "104/104 [==============================] - 13s 121ms/step - loss: 0.0655 - auc_11: 0.9968 - val_loss: 0.4418 - val_auc_11: 0.8819\n",
      "Epoch 35/50\n",
      "104/104 [==============================] - 12s 112ms/step - loss: 0.0658 - auc_11: 0.9966 - val_loss: 0.4340 - val_auc_11: 0.8936\n",
      "Epoch 36/50\n",
      "104/104 [==============================] - 12s 117ms/step - loss: 0.0644 - auc_11: 0.9968 - val_loss: 0.5160 - val_auc_11: 0.8724\n",
      "Epoch 37/50\n",
      "104/104 [==============================] - 13s 121ms/step - loss: 0.0631 - auc_11: 0.9970 - val_loss: 0.4039 - val_auc_11: 0.9003\n",
      "Epoch 38/50\n",
      "104/104 [==============================] - 11s 108ms/step - loss: 0.0629 - auc_11: 0.9971 - val_loss: 0.5242 - val_auc_11: 0.8898\n",
      "Epoch 39/50\n",
      "104/104 [==============================] - 10s 100ms/step - loss: 0.0634 - auc_11: 0.9969 - val_loss: 0.5259 - val_auc_11: 0.8725\n",
      "Epoch 40/50\n",
      "104/104 [==============================] - 12s 111ms/step - loss: 0.0622 - auc_11: 0.9972 - val_loss: 0.4827 - val_auc_11: 0.8843\n",
      "Epoch 41/50\n",
      "104/104 [==============================] - 11s 103ms/step - loss: 0.0617 - auc_11: 0.9972 - val_loss: 0.3645 - val_auc_11: 0.9048\n",
      "Epoch 42/50\n",
      "104/104 [==============================] - 11s 107ms/step - loss: 0.0623 - auc_11: 0.9972 - val_loss: 0.6067 - val_auc_11: 0.8670\n",
      "Epoch 43/50\n",
      "104/104 [==============================] - 11s 106ms/step - loss: 0.0634 - auc_11: 0.9970 - val_loss: 0.6897 - val_auc_11: 0.8579\n",
      "Epoch 44/50\n",
      "104/104 [==============================] - 11s 103ms/step - loss: 0.0618 - auc_11: 0.9973 - val_loss: 0.3885 - val_auc_11: 0.9051\n",
      "Epoch 45/50\n",
      "104/104 [==============================] - 11s 104ms/step - loss: 0.0620 - auc_11: 0.9973 - val_loss: 0.6231 - val_auc_11: 0.8630\n",
      "Epoch 46/50\n",
      "104/104 [==============================] - 12s 111ms/step - loss: 0.0615 - auc_11: 0.9973 - val_loss: 0.7374 - val_auc_11: 0.8575\n",
      "Epoch 47/50\n",
      "104/104 [==============================] - 12s 111ms/step - loss: 0.0609 - auc_11: 0.9972 - val_loss: 0.5562 - val_auc_11: 0.8740\n",
      "Epoch 48/50\n",
      "104/104 [==============================] - 12s 112ms/step - loss: 0.0621 - auc_11: 0.9972 - val_loss: 0.6153 - val_auc_11: 0.8615\n",
      "Epoch 49/50\n",
      "104/104 [==============================] - 11s 107ms/step - loss: 0.0586 - auc_11: 0.9976 - val_loss: 0.5747 - val_auc_11: 0.8824\n",
      "Epoch 50/50\n",
      "104/104 [==============================] - 11s 103ms/step - loss: 0.0575 - auc_11: 0.9978 - val_loss: 0.6749 - val_auc_11: 0.8664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1433fea30>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=[tf.keras.metrics.AUC()])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353/353 [==============================] - 2s 7ms/step - loss: 0.0467 - auc_11: 0.9977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04665688797831535, 0.9977399110794067]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-23-5d33cdcb04d1>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "y_prediction = model.predict_classes(X_pred)\n",
    "prediction = pd.DataFrame(y_prediction, columns=['target']).to_csv('/Users/yimingzhao/Desktop/prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD (Ignore first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Stochastic Gradient Descent(SGD) classifier\n",
    "# https://www.kaggle.com/sikora507/mnist-binary-classifier-precision-and-recall\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5141, 28, 28, 1)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.reshape(X_train, [4030544, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4030544, 5141]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-6b4f3b7397ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msgd_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGDClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msgd_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mskfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    706\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         \"\"\"\n\u001b[0;32m--> 708\u001b[0;31m         return self._fit(X, y, alpha=self.alpha, C=1.0,\n\u001b[0m\u001b[1;32m    709\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         X, y = check_X_y(X, y, 'csr', dtype=np.float64, order=\"C\",\n\u001b[0m\u001b[1;32m    525\u001b[0m                          accept_large_sparse=False)\n\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    212\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4030544, 5141]"
     ]
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=3, random_state=42)\n",
    "\n",
    "i=0;\n",
    "for train_index, test_index in skfolds.split(X_train, y_train):\n",
    "    clone_clf = clone(sgd_clf)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = y_train[train_index]\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = y_train[test_index]\n",
    "    \n",
    "    clone_clf.fit(X_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(\"Correct ratio for fold {1}: {0}\".format(n_correct / len(y_pred), i))\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
